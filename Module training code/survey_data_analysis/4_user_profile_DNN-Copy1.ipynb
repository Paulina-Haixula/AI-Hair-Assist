{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a812096-608f-4ba8-a968-8c10f49ed292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User profile using DNN Model\n",
    "\n",
    "## Importing Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "# 1. Import encoded dataset\n",
    "\n",
    "d5f = pd.read_csv('haircare_encoded_final2.csv')\n",
    "d5f2 = pd.read_csv('hair Care Survey_v2 (Responses) - Form responses 1.csv')\n",
    "\n",
    "\n",
    "\n",
    "# 2. Data cleaning\n",
    "\n",
    "# Clean column names: strip whitespace, convert to lowercase, replace spaces and special chars\n",
    "\n",
    "# Drop irrelevant columns (e.g., email, survey codes, etc.)\n",
    "columns_to_drop = [\n",
    "    'Timestamp', 'Score', 'Email', 'Email address',\n",
    "    \"SurveyCircle  \\n  'Thank-you-for-your-participation' page. Please use the following text line that contains your Survey Code:\",\n",
    "    'Column 53', 'Would you participate in follow-up studies?'\n",
    "]\n",
    "\n",
    "\n",
    "d5f2.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "#Normalize Text Columns: Strip whitespace, Lowercase, Remove special character\n",
    "d5f2.columns = (\n",
    "    d5f2.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(' ', '_')\n",
    "    .str.replace('[^a-zA-Z0-9_]', '', regex=True)\n",
    ")\n",
    "\n",
    "# 3. Data encoding\n",
    "\n",
    "# Define columns to encode,\n",
    "\n",
    "numeric_columns = [ 'consumed_waterday_l']\n",
    "\n",
    "ordinal_columns = [ 'current_hair_condition', 'age', 'hair_porosity','hair_texture', 'hair_density', 'harline_condition',\n",
    "                 'hair_breakage', 'hair_loss_state','hair_length_current_hair_length', 'hair_length_hair_goal', 'country', 'hair_type',\n",
    "                  'how_often_do_you_heatstyling_tools', 'how_often_do_you_tight_hairstyle', 'how_often_do_you_hair_moisturizer',\n",
    "       'how_often_do_you_scalp_massages', 'how_often_do_you_hair_wash',\n",
    "       'occurrence_of_hair_breakage', 'causes_of_hair_breakage', 'occurrence_of_hair_breakage']\n",
    "\n",
    "norminal_columns = [ 'race', 'gender', 'hair_edges_condition','hair_look', 'scalp_condition',\n",
    "                    'is_your_hair_chemically_treated',\n",
    "       'professional_treatments', 'protective_hairstyles_no_1','protective_hairstyles_no_2', 'condition_of_protective_hairstyles_used',\n",
    "       'protective_hairstyles_maintenance','causes_of_hair_breakage',  'comb_type','detangling_style', 'eating_diet',\n",
    "       'hair_state_and_their_cause_hydrated__healthy',\n",
    "       'hair_state_and_their_cause_promote_frizzy',\n",
    "       'hair_state_and_their_cause_tangled',\n",
    "       'hair_state_and_their_cause_dryness__breaking']\n",
    "\n",
    "sentence_columns = [ 'ingredient_promotes_your_hair_health','other_please_specify','hair_supplement_used',\n",
    "                      'medication_or_condition_affecting_hair_growth','hair_or_scalp_allergies',\n",
    "                       'tips_or_products_have_worked_well_for_your_hair', 'main_factor_influencing_your_hair_health_or_growth']\n",
    "Binary_columns = ['keratin_treatment', 'family_history_of_hair_loss_or_slow_growth', 'satin_scarfbonnet_or_pillowcase', ]\n",
    "\n",
    "\n",
    "#df = d5f2.copy(deep=True)\n",
    "# -----------------------------------------------------\n",
    "# 1. Numerical Column(s)\n",
    "# -----------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. Ordinal Columns → Gray Encoding\n",
    "# -----------------------------------------------------\n",
    "def to_gray_code(n):\n",
    "    return n ^ (n >> 1)\n",
    "\n",
    "def ordinal_to_gray(series):\n",
    "    unique_vals = sorted(series.dropna().unique())\n",
    "    mapping = {val: i for i, val in enumerate(unique_vals)}\n",
    "    return series.map(mapping).fillna(0).astype(int).apply(to_gray_code)\n",
    "\n",
    "for col in ordinal_columns:\n",
    "    df[col] = ordinal_to_gray(df[col])\n",
    "    #df[col] = ordinal_to_gray(df[col].astype(str).str.lower().str.strip())\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. Nominal Columns → Binary Encoding\n",
    "# -----------------------------------------------------\n",
    "\n",
    "def binary_encode_column(df, column):\n",
    "    df[column] = df[column].astype(str).str.lower().str.strip()\n",
    "\n",
    "    # If only 1 unique non-null value, skip encoding\n",
    "    if df[column].nunique(dropna=True) <= 1:\n",
    "        return pd.DataFrame(index=df.index)  # empty frame, safe for concat\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    arr = lb.fit_transform(df[column])\n",
    "\n",
    "    # Ensure arr is 2D\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr.reshape(-1, 1)\n",
    "\n",
    "    # Create matching column names for the number of array columns\n",
    "    col_names = [f\"{column}_{cls}\" for cls in lb.classes_]\n",
    "    if len(col_names) != arr.shape[1]:\n",
    "        col_names = col_names[:arr.shape[1]]\n",
    "\n",
    "    return pd.DataFrame(arr, columns=col_names, index=df.index)\n",
    "\n",
    "\n",
    "binary_encoded_nominals = [binary_encode_column(df, col) for col in norminal_columns]\n",
    "df_nominal_binary = pd.concat(binary_encoded_nominals, axis=1)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. Binary Columns → Yes/No Mapping\n",
    "# -----------------------------------------------------\n",
    "binary_map = {'yes': 1, 'no': 0}\n",
    "for col in Binary_columns:\n",
    "    df[col] = df[col].astype(str).str.lower().str.strip().map(binary_map).fillna(0).astype(int)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. Final Dataset\n",
    "# -----------------------------------------------------\n",
    "df_final = pd.concat([\n",
    "    df[numeric_columns + ordinal_columns + Binary_columns], \n",
    "    df_nominal_binary.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "print(\"Final encoded dataset shape:\", df_final.shape)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelBinarizer\n",
    "\n",
    "df = d5f2.copy(deep=True)\n",
    "\n",
    "\n",
    "class SurveyEncoder:\n",
    "    def __init__(self, numeric_columns, ordinal_columns, nominal_columns, binary_columns):\n",
    "        self.numeric_columns = numeric_columns\n",
    "        self.ordinal_columns = ordinal_columns\n",
    "        self.nominal_columns = nominal_columns\n",
    "        self.binary_columns = binary_columns\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        self.ordinal_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "        self.nominal_encoders = {}\n",
    "        self.fitted = False\n",
    "\n",
    "    def binary_encode_column(self, series, col):\n",
    "        series = series.astype(str).str.lower().str.strip()\n",
    "\n",
    "        if series.nunique(dropna=True) <= 1:\n",
    "            return pd.DataFrame(index=series.index)  # empty frame\n",
    "\n",
    "        lb = LabelBinarizer()\n",
    "        arr = lb.fit_transform(series)\n",
    "\n",
    "        # Ensure arr is 2D\n",
    "        if arr.ndim == 1:\n",
    "            arr = arr.reshape(-1, 1)\n",
    "\n",
    "        # Handle binary vs multi-class properly\n",
    "        if len(lb.classes_) == 2:\n",
    "            col_names = [f\"{col}_{lb.classes_[1]}\"]  # single column for positive class\n",
    "        else:\n",
    "            col_names = [f\"{col}_{cls}\" for cls in lb.classes_]\n",
    "\n",
    "        df_enc = pd.DataFrame(arr, columns=col_names, index=series.index)\n",
    "\n",
    "        self.nominal_encoders[col] = lb\n",
    "        return df_enc\n",
    "\n",
    "    def fit(self, df):\n",
    "        # Fit scaler for numeric\n",
    "        self.scaler.fit(df[self.numeric_columns])\n",
    "\n",
    "        # Fit ordinal encoder\n",
    "        self.ordinal_encoder.fit(df[self.ordinal_columns])\n",
    "\n",
    "        # Fit label binarizers for nominal and binary\n",
    "        for col in self.nominal_columns + self.binary_columns:\n",
    "            _ = self.binary_encode_column(df[col], col)\n",
    "\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Encoder must be fitted before transform.\")\n",
    "\n",
    "        parts = []\n",
    "\n",
    "        # Numeric\n",
    "        num_scaled = self.scaler.transform(df[self.numeric_columns])\n",
    "        parts.append(pd.DataFrame(num_scaled, columns=self.numeric_columns, index=df.index))\n",
    "\n",
    "        # Ordinal\n",
    "        ord_enc = self.ordinal_encoder.transform(df[self.ordinal_columns])\n",
    "        parts.append(pd.DataFrame(ord_enc, columns=self.ordinal_columns, index=df.index))\n",
    "\n",
    "        # Nominal + Binary\n",
    "        for col in self.nominal_columns + self.binary_columns:\n",
    "            series = df[col].astype(str).str.lower().str.strip()\n",
    "            lb = self.nominal_encoders[col]\n",
    "            arr = lb.transform(series)\n",
    "\n",
    "            if arr.ndim == 1:\n",
    "                arr = arr.reshape(-1, 1)\n",
    "\n",
    "            if len(lb.classes_) == 2:\n",
    "                col_names = [f\"{col}_{lb.classes_[1]}\"]\n",
    "            else:\n",
    "                col_names = [f\"{col}_{cls}\" for cls in lb.classes_]\n",
    "\n",
    "            parts.append(pd.DataFrame(arr, columns=col_names, index=df.index))\n",
    "\n",
    "        return pd.concat(parts, axis=1)\n",
    "\n",
    "    def fit_transform(self, df):\n",
    "        self.fit(df)\n",
    "        return self.transform(df)\n",
    "\n",
    "\n",
    "\n",
    "encoder = SurveyEncoder(numeric_columns, ordinal_columns, norminal_columns,Binary_columns)\n",
    "df_final1 = encoder.fit_transform(df)\n",
    "\n",
    "# Force shape to (132, 171)\n",
    "if df_final1.shape[1] > 171:\n",
    "    # Too many columns → drop extras\n",
    "    df_final1 = df_final1.iloc[:, :171]\n",
    "elif df_final1.shape[1] < 171:\n",
    "    # Too few columns → add zeros\n",
    "    missing_cols = 171 - df_final1.shape[1]\n",
    "    for i in range(missing_cols):\n",
    "        df_final1[f\"pad_col_{i}\"] = 0\n",
    "        \n",
    "print(\"Final encoded dataset shape:\", df_final1.shape)\n",
    "joblib.dump(encoder, \"survey_encoder.pkl\")\n",
    "\n",
    "\n",
    "import dill\n",
    "\n",
    "# Saving encoder\n",
    "with open(\"survey_encoder.pkl\", \"wb\") as f:\n",
    "    dill.dump(encoder, f)\n",
    "\n",
    "\n",
    "# Loading (no need for class definition)\n",
    "with open(\"survey_encoder.pkl\", \"rb\") as f:\n",
    "    encoder = dill.load(f)\n",
    "\n",
    "# 4. Splitting data for training and testing\n",
    "\n",
    "# === Step 2: label Target Labels ===\n",
    "\n",
    "# === Check for NaNs ===\n",
    "if df_final.isnull().values.any():\n",
    "    print(\"⚠️ Found missing values — filling with 0\")\n",
    "    df_final = df_final.fillna(0)\n",
    "\n",
    "# === Step 3: Features and Target ===\n",
    "X = df_final.drop(columns=['current_hair_condition'])\n",
    "#X = df_final.drop(columns=df_final[sentence_columns])\n",
    "\n",
    "sentence_columns\n",
    "# === Label encode string targets like \"Dry\", \"Healthy\", etc. ===\n",
    "label_enc = LabelEncoder()\n",
    "dfx= d5f2.copy(deep=True)\n",
    "\n",
    "dfx['current_hair_condition'] = label_enc.fit_transform(dfx['current_hair_condition'])\n",
    "\n",
    "if dfx.isnull().values.any():\n",
    "    dfx = dfx.fillna(0)\n",
    "    \n",
    "# === Then do one-hot encoding ===\n",
    "y = df_final['current_hair_condition']\n",
    "y_cat = to_categorical(y)\n",
    "\n",
    "# === Save class names for decoding later ===\n",
    "class_names = label_enc.classes_\n",
    "\n",
    "# 5. Model training: DNN Hair health classification\n",
    "\n",
    "# === Train/Test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# === Build Model ===\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)), \n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y_cat.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# === Step 7: Add EarlyStopping to monitor val_accuracy ===\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class AccuracyThresholdCallback(Callback):\n",
    "    def __init__(self, threshold=00.6471):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        if val_acc is not None and val_acc > self.threshold:\n",
    "            print(f\"\\n✅ Reached {val_acc:.2f} validation accuracy. Stopping training.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "\n",
    "acc_threshold = AccuracyThresholdCallback(threshold=0.75)\n",
    "\n",
    "# === Step 8: Train the model ===\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    callbacks=[acc_threshold],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# === Train Model ===\n",
    "#model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "# 6. Evaluate the Model\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 7. Save the DNN Hair health classification model\n",
    "\n",
    " model.save(\"DNN_hair_Health_classifier.h5\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf310)",
   "language": "python",
   "name": "tf310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
