{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12dbf513-697c-4868-96b6-3f88a1ce87d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3. User profile Training the GNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff055b8-f20a-407d-be1b-24a1139bb8e9",
   "metadata": {},
   "source": [
    "#  Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0f5f85-086f-423f-8ab7-bc5e68851680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c635e3-960f-4364-9ddd-e977044bd688",
   "metadata": {},
   "source": [
    "# 1. Import encoded dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb1721b-0d3a-4b69-85dc-72aab37712be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumed_waterday_l</th>\n",
       "      <th>current_hair_condition</th>\n",
       "      <th>age</th>\n",
       "      <th>hair_porosity</th>\n",
       "      <th>hair_texture</th>\n",
       "      <th>hair_density</th>\n",
       "      <th>harline_condition</th>\n",
       "      <th>hair_breakage</th>\n",
       "      <th>hair_loss_state</th>\n",
       "      <th>hair_length_current_hair_length</th>\n",
       "      <th>...</th>\n",
       "      <th>use_embed_3574</th>\n",
       "      <th>use_embed_3575</th>\n",
       "      <th>use_embed_3576</th>\n",
       "      <th>use_embed_3577</th>\n",
       "      <th>use_embed_3578</th>\n",
       "      <th>use_embed_3579</th>\n",
       "      <th>use_embed_3580</th>\n",
       "      <th>use_embed_3581</th>\n",
       "      <th>use_embed_3582</th>\n",
       "      <th>use_embed_3583</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015701</td>\n",
       "      <td>-0.097407</td>\n",
       "      <td>0.064168</td>\n",
       "      <td>0.018853</td>\n",
       "      <td>0.016023</td>\n",
       "      <td>0.021620</td>\n",
       "      <td>-0.030467</td>\n",
       "      <td>-0.082919</td>\n",
       "      <td>0.027047</td>\n",
       "      <td>0.022251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.195136</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019354</td>\n",
       "      <td>-0.105700</td>\n",
       "      <td>0.083065</td>\n",
       "      <td>-0.033938</td>\n",
       "      <td>-0.005165</td>\n",
       "      <td>-0.047516</td>\n",
       "      <td>-0.006168</td>\n",
       "      <td>0.029866</td>\n",
       "      <td>0.032657</td>\n",
       "      <td>-0.024623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.195136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062959</td>\n",
       "      <td>-0.082641</td>\n",
       "      <td>0.057330</td>\n",
       "      <td>-0.006855</td>\n",
       "      <td>-0.050399</td>\n",
       "      <td>-0.035920</td>\n",
       "      <td>0.010174</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>0.022427</td>\n",
       "      <td>-0.059028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.216102</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052985</td>\n",
       "      <td>-0.088383</td>\n",
       "      <td>0.016733</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>-0.050175</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.041893</td>\n",
       "      <td>0.021341</td>\n",
       "      <td>-0.047707</td>\n",
       "      <td>-0.025795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.017613</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074204</td>\n",
       "      <td>-0.096372</td>\n",
       "      <td>0.018246</td>\n",
       "      <td>0.040669</td>\n",
       "      <td>-0.018792</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>-0.016291</td>\n",
       "      <td>0.051236</td>\n",
       "      <td>0.019341</td>\n",
       "      <td>-0.020074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3752 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   consumed_waterday_l  current_hair_condition  age  hair_porosity  \\\n",
       "0                  NaN                       1    1              2   \n",
       "1            -0.195136                       1    2              3   \n",
       "2            -0.195136                       1    1              3   \n",
       "3             0.216102                       6    1              1   \n",
       "4            -1.017613                       6    1              3   \n",
       "\n",
       "   hair_texture  hair_density  harline_condition  hair_breakage  \\\n",
       "0             3             2                  6              2   \n",
       "1             3             3                  1              2   \n",
       "2             3             3                  1              7   \n",
       "3             1             1                  0              3   \n",
       "4             1             2                  1              2   \n",
       "\n",
       "   hair_loss_state  hair_length_current_hair_length  ...  use_embed_3574  \\\n",
       "0                0                                3  ...        0.015701   \n",
       "1                1                                5  ...        0.019354   \n",
       "2                1                                5  ...        0.062959   \n",
       "3                1                                6  ...       -0.052985   \n",
       "4                2                                3  ...        0.074204   \n",
       "\n",
       "   use_embed_3575  use_embed_3576  use_embed_3577  use_embed_3578  \\\n",
       "0       -0.097407        0.064168        0.018853        0.016023   \n",
       "1       -0.105700        0.083065       -0.033938       -0.005165   \n",
       "2       -0.082641        0.057330       -0.006855       -0.050399   \n",
       "3       -0.088383        0.016733        0.005497       -0.050175   \n",
       "4       -0.096372        0.018246        0.040669       -0.018792   \n",
       "\n",
       "   use_embed_3579  use_embed_3580  use_embed_3581  use_embed_3582  \\\n",
       "0        0.021620       -0.030467       -0.082919        0.027047   \n",
       "1       -0.047516       -0.006168        0.029866        0.032657   \n",
       "2       -0.035920        0.010174        0.005829        0.022427   \n",
       "3        0.006881        0.041893        0.021341       -0.047707   \n",
       "4        0.005182       -0.016291        0.051236        0.019341   \n",
       "\n",
       "   use_embed_3583  \n",
       "0        0.022251  \n",
       "1       -0.024623  \n",
       "2       -0.059028  \n",
       "3       -0.025795  \n",
       "4       -0.020074  \n",
       "\n",
       "[5 rows x 3752 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('haircare_encoded_final2.csv')\n",
    "df2 = pd.read_csv('hair Care Survey_v2 (Responses) - Form responses 1.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90286a4-88fe-4046-9d42-74b5e28c71c6",
   "metadata": {},
   "source": [
    "# 2. Data cleaning and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c20b97-6da7-4142-adaf-3f041889766a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Found missing values — filling with 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Check for NaNs ===\n",
    "if df.isnull().values.any():\n",
    "    print(\"⚠️ Found missing values — filling with 0\")\n",
    "    df = df.fillna(0)\n",
    "\n",
    "# === Step 3: Features and Target ===\n",
    "X = df.drop(columns=['current_hair_condition'])\n",
    "\n",
    "\n",
    "# === Label encode string targets like \"Dry\", \"Healthy\", etc. ===\n",
    "label_enc = LabelEncoder()\n",
    "dfx= df2\n",
    "\n",
    "dfx['Current Hair condition'] = label_enc.fit_transform(dfx['Current Hair condition'])\n",
    "\n",
    "if dfx.isnull().values.any():\n",
    "    dfx = dfx.fillna(0)\n",
    "    \n",
    "# === Then do one-hot encoding ===\n",
    "y = dfx['Current Hair condition'].values\n",
    "y_cat = to_categorical(y)\n",
    "\n",
    "# === Save class names for decoding later ===\n",
    "class_names = label_enc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b22f54d-4ffa-4861-aaf3-cb59ee445858",
   "metadata": {},
   "source": [
    "# 3. Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e01d548a-5276-4a3f-9e83-06a499b1945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Create Graph Structure ===\n",
    "def create_graph_data(X, y):\n",
    "    x = torch.tensor(X, dtype=torch.float)\n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    # Fully connect all nodes (this is basic; better graphs can use k-NN or similarity)\n",
    "    edge_index = torch.combinations(torch.arange(x.size(0)), r=2).T\n",
    "    edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)  # Make it bidirectional\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "train_data = create_graph_data(X_train, y_train)\n",
    "test_data = create_graph_data(X_test, y_test)\n",
    "\n",
    "# ===  Define GNN Model ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class HaircareGCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(HaircareGCN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b5a8f-7455-4395-a7e0-e3f8a0152163",
   "metadata": {},
   "source": [
    "# 4. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02669c72-7847-4123-a1fe-acd09894ace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n",
      "\n",
      "Epoch   1 | Train Loss: 1.7289 | Train Acc: 0.0667 | Val Loss: 2.8750 | Val Acc: 0.2222\n",
      "Epoch   2 | Train Loss: 1.4537 | Train Acc: 0.4857 | Val Loss: 2.9783 | Val Acc: 0.4074\n",
      "Epoch   3 | Train Loss: 1.4425 | Train Acc: 0.7333 | Val Loss: 4.4392 | Val Acc: 0.2222\n",
      "Epoch   4 | Train Loss: 1.2146 | Train Acc: 0.7429 | Val Loss: 4.9518 | Val Acc: 0.2222\n",
      "Epoch   5 | Train Loss: 0.9231 | Train Acc: 0.8571 | Val Loss: 5.0320 | Val Acc: 0.3704\n",
      "Epoch   6 | Train Loss: 0.7488 | Train Acc: 0.8476 | Val Loss: 5.1131 | Val Acc: 0.3333\n",
      "Epoch   7 | Train Loss: 0.6863 | Train Acc: 0.8571 | Val Loss: 5.1246 | Val Acc: 0.2593\n",
      "Epoch   8 | Train Loss: 0.5422 | Train Acc: 0.8857 | Val Loss: 5.0016 | Val Acc: 0.2593\n",
      "Epoch   9 | Train Loss: 0.5369 | Train Acc: 0.8952 | Val Loss: 4.7838 | Val Acc: 0.2593\n",
      "Epoch  10 | Train Loss: 0.4195 | Train Acc: 0.9429 | Val Loss: 4.7363 | Val Acc: 0.2963\n",
      "Epoch  11 | Train Loss: 0.3147 | Train Acc: 0.9238 | Val Loss: 5.0813 | Val Acc: 0.2593\n",
      "Epoch  12 | Train Loss: 0.1769 | Train Acc: 0.9524 | Val Loss: 5.5066 | Val Acc: 0.2222\n",
      "Epoch  13 | Train Loss: 0.1797 | Train Acc: 0.9238 | Val Loss: 5.7318 | Val Acc: 0.2222\n",
      "Epoch  14 | Train Loss: 0.3136 | Train Acc: 0.8476 | Val Loss: 5.4863 | Val Acc: 0.2593\n",
      "Epoch  15 | Train Loss: 0.1347 | Train Acc: 0.9714 | Val Loss: 5.2556 | Val Acc: 0.2963\n",
      "Epoch  16 | Train Loss: 0.1855 | Train Acc: 0.9524 | Val Loss: 5.2422 | Val Acc: 0.2963\n",
      "Epoch  17 | Train Loss: 0.2253 | Train Acc: 0.9333 | Val Loss: 5.4887 | Val Acc: 0.3333\n",
      "Epoch  18 | Train Loss: 0.1522 | Train Acc: 0.9619 | Val Loss: 5.8355 | Val Acc: 0.3333\n",
      "Epoch  19 | Train Loss: 0.0971 | Train Acc: 0.9714 | Val Loss: 6.1103 | Val Acc: 0.3333\n",
      "Epoch  20 | Train Loss: 0.1125 | Train Acc: 0.9619 | Val Loss: 6.2332 | Val Acc: 0.3333\n",
      "Epoch  21 | Train Loss: 0.1274 | Train Acc: 0.9429 | Val Loss: 6.2187 | Val Acc: 0.3333\n",
      "Epoch  22 | Train Loss: 0.0541 | Train Acc: 0.9905 | Val Loss: 6.1667 | Val Acc: 0.3333\n",
      "Epoch  23 | Train Loss: 0.0394 | Train Acc: 1.0000 | Val Loss: 6.1592 | Val Acc: 0.3333\n",
      "Epoch  24 | Train Loss: 0.0596 | Train Acc: 0.9905 | Val Loss: 6.2287 | Val Acc: 0.3333\n",
      "Epoch  25 | Train Loss: 0.0746 | Train Acc: 0.9810 | Val Loss: 6.3563 | Val Acc: 0.3333\n",
      "Epoch  26 | Train Loss: 0.0728 | Train Acc: 0.9810 | Val Loss: 6.4940 | Val Acc: 0.3333\n",
      "Epoch  27 | Train Loss: 0.0574 | Train Acc: 0.9810 | Val Loss: 6.6074 | Val Acc: 0.3333\n",
      "Epoch  28 | Train Loss: 0.0352 | Train Acc: 1.0000 | Val Loss: 6.6859 | Val Acc: 0.3333\n",
      "Epoch  29 | Train Loss: 0.0220 | Train Acc: 1.0000 | Val Loss: 6.7385 | Val Acc: 0.3333\n",
      "Epoch  30 | Train Loss: 0.0207 | Train Acc: 1.0000 | Val Loss: 6.7870 | Val Acc: 0.3333\n",
      "Epoch  31 | Train Loss: 0.0289 | Train Acc: 1.0000 | Val Loss: 6.8447 | Val Acc: 0.3333\n",
      "Epoch  32 | Train Loss: 0.0359 | Train Acc: 1.0000 | Val Loss: 6.9162 | Val Acc: 0.3333\n",
      "Epoch  33 | Train Loss: 0.0278 | Train Acc: 1.0000 | Val Loss: 6.9894 | Val Acc: 0.3333\n",
      "Epoch  34 | Train Loss: 0.0190 | Train Acc: 1.0000 | Val Loss: 7.0463 | Val Acc: 0.3333\n",
      "Epoch  35 | Train Loss: 0.0160 | Train Acc: 1.0000 | Val Loss: 7.0768 | Val Acc: 0.3333\n",
      "Epoch  36 | Train Loss: 0.0148 | Train Acc: 1.0000 | Val Loss: 7.0789 | Val Acc: 0.3333\n",
      "Epoch  37 | Train Loss: 0.0135 | Train Acc: 1.0000 | Val Loss: 7.0573 | Val Acc: 0.3333\n",
      "Epoch  38 | Train Loss: 0.0123 | Train Acc: 1.0000 | Val Loss: 7.0330 | Val Acc: 0.3333\n",
      "Epoch  39 | Train Loss: 0.0122 | Train Acc: 1.0000 | Val Loss: 7.0239 | Val Acc: 0.3333\n",
      "Epoch  40 | Train Loss: 0.0125 | Train Acc: 1.0000 | Val Loss: 7.0409 | Val Acc: 0.3333\n",
      "Epoch  41 | Train Loss: 0.0122 | Train Acc: 1.0000 | Val Loss: 7.0864 | Val Acc: 0.3333\n",
      "Epoch  42 | Train Loss: 0.0110 | Train Acc: 1.0000 | Val Loss: 7.1535 | Val Acc: 0.3333\n",
      "Epoch  43 | Train Loss: 0.0093 | Train Acc: 1.0000 | Val Loss: 7.2299 | Val Acc: 0.3333\n",
      "Epoch  44 | Train Loss: 0.0080 | Train Acc: 1.0000 | Val Loss: 7.3028 | Val Acc: 0.3333\n",
      "Epoch  45 | Train Loss: 0.0072 | Train Acc: 1.0000 | Val Loss: 7.3625 | Val Acc: 0.3333\n",
      "Epoch  46 | Train Loss: 0.0068 | Train Acc: 1.0000 | Val Loss: 7.4035 | Val Acc: 0.3333\n",
      "Epoch  47 | Train Loss: 0.0064 | Train Acc: 1.0000 | Val Loss: 7.4237 | Val Acc: 0.3333\n",
      "Epoch  48 | Train Loss: 0.0059 | Train Acc: 1.0000 | Val Loss: 7.4270 | Val Acc: 0.3333\n",
      "Epoch  49 | Train Loss: 0.0054 | Train Acc: 1.0000 | Val Loss: 7.4195 | Val Acc: 0.3333\n",
      "Epoch  50 | Train Loss: 0.0050 | Train Acc: 1.0000 | Val Loss: 7.4083 | Val Acc: 0.3333\n",
      "Epoch  51 | Train Loss: 0.0047 | Train Acc: 1.0000 | Val Loss: 7.3997 | Val Acc: 0.3333\n",
      "Epoch  52 | Train Loss: 0.0046 | Train Acc: 1.0000 | Val Loss: 7.3977 | Val Acc: 0.3333\n",
      "Epoch  53 | Train Loss: 0.0045 | Train Acc: 1.0000 | Val Loss: 7.4043 | Val Acc: 0.3333\n",
      "Epoch  54 | Train Loss: 0.0043 | Train Acc: 1.0000 | Val Loss: 7.4189 | Val Acc: 0.3333\n",
      "Epoch  55 | Train Loss: 0.0041 | Train Acc: 1.0000 | Val Loss: 7.4392 | Val Acc: 0.3333\n",
      "Epoch  56 | Train Loss: 0.0038 | Train Acc: 1.0000 | Val Loss: 7.4617 | Val Acc: 0.3333\n",
      "Epoch  57 | Train Loss: 0.0036 | Train Acc: 1.0000 | Val Loss: 7.4830 | Val Acc: 0.3333\n",
      "Epoch  58 | Train Loss: 0.0035 | Train Acc: 1.0000 | Val Loss: 7.5003 | Val Acc: 0.3333\n",
      "Epoch  59 | Train Loss: 0.0034 | Train Acc: 1.0000 | Val Loss: 7.5116 | Val Acc: 0.3333\n",
      "Epoch  60 | Train Loss: 0.0032 | Train Acc: 1.0000 | Val Loss: 7.5165 | Val Acc: 0.3333\n",
      "Epoch  61 | Train Loss: 0.0031 | Train Acc: 1.0000 | Val Loss: 7.5156 | Val Acc: 0.3333\n",
      "Epoch  62 | Train Loss: 0.0029 | Train Acc: 1.0000 | Val Loss: 7.5105 | Val Acc: 0.3333\n",
      "Epoch  63 | Train Loss: 0.0027 | Train Acc: 1.0000 | Val Loss: 7.5033 | Val Acc: 0.3333\n",
      "Epoch  64 | Train Loss: 0.0026 | Train Acc: 1.0000 | Val Loss: 7.4962 | Val Acc: 0.3333\n",
      "Epoch  65 | Train Loss: 0.0025 | Train Acc: 1.0000 | Val Loss: 7.4912 | Val Acc: 0.3333\n",
      "Epoch  66 | Train Loss: 0.0024 | Train Acc: 1.0000 | Val Loss: 7.4895 | Val Acc: 0.3333\n",
      "Epoch  67 | Train Loss: 0.0023 | Train Acc: 1.0000 | Val Loss: 7.4921 | Val Acc: 0.3333\n",
      "Epoch  68 | Train Loss: 0.0023 | Train Acc: 1.0000 | Val Loss: 7.4989 | Val Acc: 0.3333\n",
      "Epoch  69 | Train Loss: 0.0022 | Train Acc: 1.0000 | Val Loss: 7.5095 | Val Acc: 0.3333\n",
      "Epoch  70 | Train Loss: 0.0022 | Train Acc: 1.0000 | Val Loss: 7.5228 | Val Acc: 0.3333\n",
      "Epoch  71 | Train Loss: 0.0021 | Train Acc: 1.0000 | Val Loss: 7.5375 | Val Acc: 0.3333\n",
      "Epoch  72 | Train Loss: 0.0020 | Train Acc: 1.0000 | Val Loss: 7.5524 | Val Acc: 0.3333\n",
      "Epoch  73 | Train Loss: 0.0020 | Train Acc: 1.0000 | Val Loss: 7.5663 | Val Acc: 0.3333\n",
      "Epoch  74 | Train Loss: 0.0020 | Train Acc: 1.0000 | Val Loss: 7.5782 | Val Acc: 0.3333\n",
      "Epoch  75 | Train Loss: 0.0019 | Train Acc: 1.0000 | Val Loss: 7.5874 | Val Acc: 0.3333\n",
      "Epoch  76 | Train Loss: 0.0019 | Train Acc: 1.0000 | Val Loss: 7.5939 | Val Acc: 0.3333\n",
      "Epoch  77 | Train Loss: 0.0019 | Train Acc: 1.0000 | Val Loss: 7.5976 | Val Acc: 0.3333\n",
      "Epoch  78 | Train Loss: 0.0018 | Train Acc: 1.0000 | Val Loss: 7.5990 | Val Acc: 0.3333\n",
      "Epoch  79 | Train Loss: 0.0018 | Train Acc: 1.0000 | Val Loss: 7.5988 | Val Acc: 0.3333\n",
      "Epoch  80 | Train Loss: 0.0017 | Train Acc: 1.0000 | Val Loss: 7.5978 | Val Acc: 0.3333\n",
      "Epoch  81 | Train Loss: 0.0017 | Train Acc: 1.0000 | Val Loss: 7.5965 | Val Acc: 0.3333\n",
      "Epoch  82 | Train Loss: 0.0016 | Train Acc: 1.0000 | Val Loss: 7.5958 | Val Acc: 0.3333\n",
      "Epoch  83 | Train Loss: 0.0016 | Train Acc: 1.0000 | Val Loss: 7.5961 | Val Acc: 0.3333\n",
      "Epoch  84 | Train Loss: 0.0016 | Train Acc: 1.0000 | Val Loss: 7.5976 | Val Acc: 0.3333\n",
      "Epoch  85 | Train Loss: 0.0015 | Train Acc: 1.0000 | Val Loss: 7.6006 | Val Acc: 0.3333\n",
      "Epoch  86 | Train Loss: 0.0015 | Train Acc: 1.0000 | Val Loss: 7.6049 | Val Acc: 0.3333\n",
      "Epoch  87 | Train Loss: 0.0015 | Train Acc: 1.0000 | Val Loss: 7.6103 | Val Acc: 0.3333\n",
      "Epoch  88 | Train Loss: 0.0014 | Train Acc: 1.0000 | Val Loss: 7.6164 | Val Acc: 0.3333\n",
      "Epoch  89 | Train Loss: 0.0014 | Train Acc: 1.0000 | Val Loss: 7.6227 | Val Acc: 0.3333\n",
      "Epoch  90 | Train Loss: 0.0014 | Train Acc: 1.0000 | Val Loss: 7.6289 | Val Acc: 0.3333\n",
      "Epoch  91 | Train Loss: 0.0014 | Train Acc: 1.0000 | Val Loss: 7.6346 | Val Acc: 0.3333\n",
      "Epoch  92 | Train Loss: 0.0014 | Train Acc: 1.0000 | Val Loss: 7.6396 | Val Acc: 0.3333\n",
      "Epoch  93 | Train Loss: 0.0013 | Train Acc: 1.0000 | Val Loss: 7.6436 | Val Acc: 0.3333\n",
      "Epoch  94 | Train Loss: 0.0013 | Train Acc: 1.0000 | Val Loss: 7.6467 | Val Acc: 0.3333\n",
      "Epoch  95 | Train Loss: 0.0013 | Train Acc: 1.0000 | Val Loss: 7.6488 | Val Acc: 0.3333\n",
      "Epoch  96 | Train Loss: 0.0013 | Train Acc: 1.0000 | Val Loss: 7.6502 | Val Acc: 0.3333\n",
      "Epoch  97 | Train Loss: 0.0013 | Train Acc: 1.0000 | Val Loss: 7.6509 | Val Acc: 0.3333\n",
      "Epoch  98 | Train Loss: 0.0012 | Train Acc: 1.0000 | Val Loss: 7.6514 | Val Acc: 0.3333\n",
      "Epoch  99 | Train Loss: 0.0012 | Train Acc: 1.0000 | Val Loss: 7.6518 | Val Acc: 0.3333\n",
      "Epoch 100 | Train Loss: 0.0012 | Train Acc: 1.0000 | Val Loss: 7.6523 | Val Acc: 0.3333\n",
      "\n",
      "=== Final Classification Report ===\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Damaged       0.33      0.33      0.33         3\n",
      "         Dry       0.67      0.38      0.48        16\n",
      "     Healthy       0.17      0.40      0.24         5\n",
      "  Moisturize       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.33        27\n",
      "   macro avg       0.29      0.28      0.26        27\n",
      "weighted avg       0.46      0.33      0.37        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Initialize Model, Optimizer, Loss ===\n",
    "model = HaircareGCN(input_dim=X.shape[1], hidden_dim=32, output_dim=len(class_names))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# === Training Loop with Validation Metrics ===\n",
    "print(\"Training Model...\\n\")\n",
    "for epoch in range(1, 101):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(train_data)\n",
    "    loss = criterion(out, train_data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # === Training Accuracy ===\n",
    "    pred_train = out.argmax(dim=1)\n",
    "    train_acc = accuracy_score(train_data.y.cpu(), pred_train.cpu())\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out_val = model(test_data)\n",
    "        val_loss = criterion(out_val, test_data.y)\n",
    "        pred_val = out_val.argmax(dim=1)\n",
    "        val_acc = accuracy_score(test_data.y.cpu(), pred_val.cpu())\n",
    "\n",
    "    # === Print Epoch Metrics ===\n",
    "    print(f\"Epoch {epoch:3d} | Train Loss: {loss.item():.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss.item():.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# === Final Evaluation ===\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_preds = model(test_data).argmax(dim=1)\n",
    "\n",
    "y_true = test_data.y.cpu().numpy()\n",
    "y_pred = final_preds.cpu().numpy()\n",
    "\n",
    "# Convert to labels\n",
    "y_true_labels = [class_names[i] for i in y_true]\n",
    "y_pred_labels = [class_names[i] for i in y_pred]\n",
    "\n",
    "# === Classification Report ===\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\n=== Final Classification Report ===\\n\")\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5306a2a7-5ed9-4db6-8fae-db60ee32cc30",
   "metadata": {},
   "source": [
    "# 5. Testing recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f355a8b8-e495-4d51-91c1-05e61523828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Haircare Recommendations Based on GNN Prediction:\n",
      "\n",
      "Sample #1\n",
      "Predicted Condition: Dry\n",
      "Actual Condition   : Healthy\n",
      "Suggested Products : ['Deep Conditioner', 'Moisturizing Hair Mask', 'Leave-in Cream']\n",
      "========================================\n",
      "Sample #2\n",
      "Predicted Condition: Dry\n",
      "Actual Condition   : Healthy\n",
      "Suggested Products : ['Deep Conditioner', 'Moisturizing Hair Mask', 'Leave-in Cream']\n",
      "========================================\n",
      "Sample #3\n",
      "Predicted Condition: Damaged\n",
      "Actual Condition   : Damaged\n",
      "Suggested Products : ['Protein Treatment', 'Split End Serum']\n",
      "========================================\n",
      "Sample #4\n",
      "Predicted Condition: Healthy\n",
      "Actual Condition   : Dry\n",
      "Suggested Products : ['Mild Shampoo', 'Light Conditioner']\n",
      "========================================\n",
      "Sample #5\n",
      "Predicted Condition: Healthy\n",
      "Actual Condition   : Healthy\n",
      "Suggested Products : ['Mild Shampoo', 'Light Conditioner']\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# === Step 6: Haircare Product Mapping ===\n",
    "product_recommendations = {\n",
    "    'dry': ['Deep Conditioner', 'Moisturizing Hair Mask', 'Leave-in Cream'],\n",
    "    'healthy': ['Mild Shampoo', 'Light Conditioner'],\n",
    "    'dandruff-prone': ['Anti-Dandruff Shampoo', 'Tea Tree Oil'],\n",
    "    'moisturize': ['Hydration Mist', 'Leave-In Conditioner'],\n",
    "    'damaged': ['Protein Treatment', 'Split End Serum'],\n",
    "    'oily': ['Clarifying Shampoo', 'Scalp Scrub'],\n",
    "    'dry and brittle': ['Hair Butter', 'Moisture Retention Treatment'],\n",
    "}\n",
    "\n",
    "# === Step 7: Sample Recommendations ===\n",
    "print(\"\\nSample Haircare Recommendations Based on GNN Prediction:\\n\")\n",
    "for i in range(min(5, len(y_pred))):\n",
    "    print(f\"Sample #{i+1}\")\n",
    "    print(\"Predicted Condition:\", y_pred_labels[i])\n",
    "    print(\"Actual Condition   :\", y_true_labels[i])\n",
    "    print(\"Suggested Products :\", product_recommendations.get(y_pred_labels[i].lower(), [\"No suggestion found\"]))\n",
    "    print(\"=\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf310)",
   "language": "python",
   "name": "tf310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
